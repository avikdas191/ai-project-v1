{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-13T14:19:59.504901200Z",
     "start_time": "2024-09-13T14:19:59.500631500Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img, ImageDataGenerator\n",
    "# from tensorflowcore\n",
    "# from tensorflow import _tf_uses_legacy_keras\n",
    "# from keras._tf_keras.keras.preprocessing.image import img_to_array, array_to_img, ImageDataGenerator\n",
    "# import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avikd\\PycharmProjects\\pythonProject0\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T14:26:31.751990500Z",
     "start_time": "2024-09-13T14:26:31.741529900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T14:27:38.668325500Z",
     "start_time": "2024-09-13T14:27:38.627143200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames from Bat.mp4...\n",
      "Extracting frames from Big.mp4...\n",
      "Extracting frames from Book.mp4...\n",
      "Extracting frames from Car.mp4...\n",
      "Extracting frames from Cat.mp4...\n",
      "Extracting frames from Cup.mp4...\n",
      "Extracting frames from Dog.mp4...\n",
      "Extracting frames from Drop.mp4...\n",
      "Extracting frames from Eat.mp4...\n",
      "Extracting frames from Fast.mp4...\n",
      "Extracting frames from Fish.mp4...\n",
      "Extracting frames from Fun.mp4...\n",
      "Extracting frames from Go.mp4...\n",
      "Extracting frames from Hat.mp4...\n",
      "Extracting frames from Hot.mp4...\n",
      "Extracting frames from Jump.mp4...\n",
      "Extracting frames from Kick.mp4...\n",
      "Extracting frames from Leg.mp4...\n",
      "Extracting frames from Milk.mp4...\n",
      "Extracting frames from No.mp4...\n",
      "Extracting frames from Pen.mp4...\n",
      "Extracting frames from Pick.mp4...\n",
      "Extracting frames from Red.mp4...\n",
      "Extracting frames from Run.mp4...\n",
      "Extracting frames from Sit.mp4...\n",
      "Extracting frames from Stop.mp4...\n",
      "Extracting frames from Sun.mp4...\n",
      "Extracting frames from Top.mp4...\n",
      "Extracting frames from Win.mp4...\n",
      "Extracting frames from Yes.mp4...\n",
      "Frame extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Path where the raw videos are stored on your local machine\n",
    "video_folder = r'D:\\pro_dis\\videos\\HD_720p'\n",
    "\n",
    "# Output folder for storing extracted frames (create a new folder for this purpose)\n",
    "output_folder = r'D:\\pro_dis\\extracted_frames'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to extract frames from videos without mouth cropping\n",
    "def extract_frames(video_path, output_dir):\n",
    "    # Open the video file\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        # Save extracted frame as an image (e.g., JPEG) without cropping\n",
    "        cv2.imwrite(f\"{output_dir}/frame{count}.jpg\", image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "\n",
    "# Process all videos in the folder\n",
    "for video_name in os.listdir(video_folder):\n",
    "    if video_name.endswith('.mp4'):  # Ensure you're only processing video files\n",
    "        video_path = os.path.join(video_folder, video_name)\n",
    "        output_dir = os.path.join(output_folder, os.path.splitext(video_name)[0])\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Extract frames from the video\n",
    "        print(f\"Extracting frames from {video_name}...\")\n",
    "        extract_frames(video_path, output_dir)\n",
    "\n",
    "print(\"Frame extraction complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T11:25:47.217394600Z",
     "start_time": "2024-09-13T11:25:12.907946800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing frames for Bat with full augmentation...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 85\u001B[0m\n\u001B[0;32m     83\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(word_frame_dir):\n\u001B[0;32m     84\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOrganizing frames for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mword_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with full augmentation...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 85\u001B[0m         \u001B[43maugment_frames_with_originals\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword_frame_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_word_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFrames organized for deep learning analysis with full augmentation!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[29], line 69\u001B[0m, in \u001B[0;36maugment_frames_with_originals\u001B[1;34m(frame_dir, output_dir)\u001B[0m\n\u001B[0;32m     66\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# Apply augmentation to the frame and save it\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m \u001B[43maugment_and_save_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcount\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mframes\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[29], line 22\u001B[0m, in \u001B[0;36maugment_and_save_frame\u001B[1;34m(image_path, output_dir, count)\u001B[0m\n\u001B[0;32m     19\u001B[0m img \u001B[38;5;241m=\u001B[39m img_to_array(img)\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Apply horizontal flipping and brightness adjustments\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m img \u001B[38;5;241m=\u001B[39m \u001B[43mdatagen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Add noise to 30% of the frames\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m random\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.3\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject0\\venv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1460\u001B[0m, in \u001B[0;36mImageDataGenerator.random_transform\u001B[1;34m(self, x, seed)\u001B[0m\n\u001B[0;32m   1450\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Applies a random transformation to an image.\u001B[39;00m\n\u001B[0;32m   1451\u001B[0m \n\u001B[0;32m   1452\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1457\u001B[0m \u001B[38;5;124;03m    A randomly transformed version of the input (same shape).\u001B[39;00m\n\u001B[0;32m   1458\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1459\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_random_transform(x\u001B[38;5;241m.\u001B[39mshape, seed)\n\u001B[1;32m-> 1460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject0\\venv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1443\u001B[0m, in \u001B[0;36mImageDataGenerator.apply_transform\u001B[1;34m(self, x, transform_parameters)\u001B[0m\n\u001B[0;32m   1440\u001B[0m     x \u001B[38;5;241m=\u001B[39m flip_axis(x, img_row_axis)\n\u001B[0;32m   1442\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transform_parameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbrightness\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1443\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mapply_brightness_shift\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbrightness\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m   1445\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1447\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject0\\venv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1728\u001B[0m, in \u001B[0;36mapply_brightness_shift\u001B[1;34m(x, brightness, scale)\u001B[0m\n\u001B[0;32m   1710\u001B[0m \u001B[38;5;129m@keras_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras._legacy.preprocessing.image.apply_brightness_shift\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1711\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_brightness_shift\u001B[39m(x, brightness, scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1712\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Performs a brightness shift.\u001B[39;00m\n\u001B[0;32m   1713\u001B[0m \n\u001B[0;32m   1714\u001B[0m \u001B[38;5;124;03m    DEPRECATED.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;124;03m        ImportError: if PIL is not available.\u001B[39;00m\n\u001B[0;32m   1727\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1728\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ImageEnhance\n\u001B[0;32m   1730\u001B[0m     x_min, x_max \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(x), np\u001B[38;5;241m.\u001B[39mmax(x)\n\u001B[0;32m   1731\u001B[0m     local_scale \u001B[38;5;241m=\u001B[39m (x_min \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (x_max \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m255\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator for basic augmentations (horizontal flip, brightness)\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]  # Adjusting brightness (color jittering)\n",
    ")\n",
    "\n",
    "# Function to apply noise to an image\n",
    "def add_noise(image):\n",
    "    row, col, ch = image.shape\n",
    "    mean = 0\n",
    "    sigma = 0.1  # Fixed sigma value (standard deviation) for Gaussian noise\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    noisy_image = np.clip(image + gauss * 255, 0, 255).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "# Function to augment and save augmented frames\n",
    "def augment_and_save_frame(image_path, output_dir, count):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    # Apply horizontal flipping and brightness adjustments\n",
    "    img = datagen.random_transform(img)\n",
    "\n",
    "    # Add noise to 30% of the frames\n",
    "    if random.random() < 0.3:\n",
    "        img = add_noise(img)\n",
    "\n",
    "    # Convert back to image format and save augmented frame with consistent naming\n",
    "    aug_img = array_to_img(img)\n",
    "    aug_img.save(f\"{output_dir}/frame{count}.jpg\")  # Augmented frame saved with sequential naming\n",
    "\n",
    "# Function to randomly shift frames temporally\n",
    "def temporal_shift(frames):\n",
    "    shift_amount = random.randint(-2, 2)  # Shift between -2 to +2 frames\n",
    "    return np.roll(frames, shift_amount, axis=0)\n",
    "\n",
    "# Function to augment frames with all techniques and keep both original and augmented frames\n",
    "def augment_frames_with_originals(frame_dir, output_dir):\n",
    "    # List all frame files in the directory\n",
    "    frames = sorted(os.listdir(frame_dir))\n",
    "\n",
    "    # Randomly remove or duplicate 10% of frames to simulate frame corruption/duplication\n",
    "    num_modify = int(0.1 * len(frames))\n",
    "    modify_indices = random.sample(range(len(frames)), num_modify)\n",
    "\n",
    "    # Read all frames into a list for easier manipulation\n",
    "    all_frames = [cv2.imread(os.path.join(frame_dir, frame)) for frame in frames]\n",
    "\n",
    "    # Apply temporal shifting to the entire sequence\n",
    "    shifted_frames = temporal_shift(np.array(all_frames))\n",
    "\n",
    "    # Save original frames to output directory\n",
    "    for count, frame_name in enumerate(frames):\n",
    "        frame_path = os.path.join(frame_dir, frame_name)\n",
    "        original_frame_path = os.path.join(output_dir, f\"frame{count}.jpg\")\n",
    "        os.system(f\"copy \\\"{frame_path}\\\" \\\"{original_frame_path}\\\"\")  # Use copy for Windows\n",
    "\n",
    "        # If the frame is selected for modification (removal or duplication)\n",
    "        if count in modify_indices:\n",
    "            if random.random() < 0.5:  # Randomly decide whether to remove or duplicate\n",
    "                # Duplicate frame (copy it again)\n",
    "                aug_img_path = os.path.join(output_dir, f\"frame{count + len(frames)}.jpg\")\n",
    "                os.system(f\"copy \\\"{original_frame_path}\\\" \\\"{aug_img_path}\\\"\")  # Duplicate the frame\n",
    "            else:\n",
    "                # Skip the frame to simulate removal\n",
    "                continue\n",
    "\n",
    "        # Apply augmentation to the frame and save it\n",
    "        augment_and_save_frame(frame_path, output_dir, count + len(frames))  # Augmented frames start after originals\n",
    "\n",
    "# Path where the raw videos are stored on your local machine\n",
    "extracted_frames_folder = r'D:\\pro_dis\\extracted_frames'  # Path where the extracted frames are stored\n",
    "\n",
    "# Output folder for organizing both original and augmented frames\n",
    "organized_frames_folder = r'D:\\pro_dis\\organized_frames'  # Output folder for augmented frames\n",
    "os.makedirs(organized_frames_folder, exist_ok=True)\n",
    "\n",
    "# Apply augmentation and store both original and augmented frames in an organized folder\n",
    "for word_dir in os.listdir(extracted_frames_folder):\n",
    "    word_frame_dir = os.path.join(extracted_frames_folder, word_dir)\n",
    "    output_word_dir = os.path.join(organized_frames_folder, word_dir)  # New output directory\n",
    "    os.makedirs(output_word_dir, exist_ok=True)  # Create output directory for each word\n",
    "    if os.path.isdir(word_frame_dir):\n",
    "        print(f\"Organizing frames for {word_dir} with full augmentation...\")\n",
    "        augment_frames_with_originals(word_frame_dir, output_word_dir)\n",
    "\n",
    "print(\"Frames organized for deep learning analysis with full augmentation!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-13T14:20:28.295312300Z",
     "start_time": "2024-09-13T14:20:27.433180400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
